{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "oL35bf4lxHQq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "789eb002-e230-4813-97bd-bf388b881bf0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import packages"
      ],
      "metadata": {
        "id": "2sZCzu1P_Ah7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "v1bJBuYkwwWQ",
        "outputId": "b29aa7ab-5d14-45de-a342-0bcbc1d5422c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (3.6.0)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.15.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (5.2.1)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.7.3)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.21.6)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/boudinfl/pke.git\n",
            "  Cloning https://github.com/boudinfl/pke.git to /tmp/pip-req-build-avuyku19\n",
            "  Running command git clone -q https://github.com/boudinfl/pke.git /tmp/pip-req-build-avuyku19\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from pke==2.0.0) (3.7)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from pke==2.0.0) (2.6.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pke==2.0.0) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from pke==2.0.0) (1.7.3)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (from pke==2.0.0) (0.0)\n",
            "Requirement already satisfied: unidecode in /usr/local/lib/python3.7/dist-packages (from pke==2.0.0) (1.3.4)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pke==2.0.0) (0.16.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from pke==2.0.0) (1.1.0)\n",
            "Requirement already satisfied: spacy>=3.2.3 in /usr/local/lib/python3.7/dist-packages (from pke==2.0.0) (3.3.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.3->pke==2.0.0) (3.0.6)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.3->pke==2.0.0) (0.7.8)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.3->pke==2.0.0) (0.4.2)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.3->pke==2.0.0) (1.8.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.3->pke==2.0.0) (21.3)\n",
            "Requirement already satisfied: thinc<8.1.0,>=8.0.14 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.3->pke==2.0.0) (8.0.17)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.3->pke==2.0.0) (3.1.2)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.3->pke==2.0.0) (2.0.6)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.3->pke==2.0.0) (2.4.3)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.3->pke==2.0.0) (2.0.7)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.3->pke==2.0.0) (1.0.7)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.3->pke==2.0.0) (3.0.9)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.3->pke==2.0.0) (4.64.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.3->pke==2.0.0) (2.28.1)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.3->pke==2.0.0) (0.6.2)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.3->pke==2.0.0) (1.0.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.3->pke==2.0.0) (63.1.0)\n",
            "Requirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.3->pke==2.0.0) (4.1.1)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.3->pke==2.0.0) (0.9.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.3->pke==2.0.0) (3.3.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy>=3.2.3->pke==2.0.0) (3.8.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy>=3.2.3->pke==2.0.0) (3.0.9)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy>=3.2.3->pke==2.0.0) (5.2.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.2.3->pke==2.0.0) (1.26.10)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.2.3->pke==2.0.0) (2.1.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.2.3->pke==2.0.0) (2022.6.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.2.3->pke==2.0.0) (3.3)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy>=3.2.3->pke==2.0.0) (8.1.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from click<9.0.0,>=7.1.1->typer<0.5.0,>=0.3.0->spacy>=3.2.3->pke==2.0.0) (4.12.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy>=3.2.3->pke==2.0.0) (2.1.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk->pke==2.0.0) (2022.7.9)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn->pke==2.0.0) (1.0.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn->pke==2.0.0) (3.1.0)\n",
            "\u001b[38;5;3m⚠ As of spaCy v3.0, shortcuts like 'en' are deprecated. Please use the\n",
            "full pipeline package name 'en_core_web_sm' instead.\u001b[0m\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting en-core-web-sm==3.3.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.3.0/en_core_web_sm-3.3.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.8 MB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy<3.4.0,>=3.3.0.dev0 in /usr/local/lib/python3.7/dist-packages (from en-core-web-sm==3.3.0) (3.3.1)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.7.8)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.8.2)\n",
            "Requirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (4.1.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.28.1)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.4.2)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.0.6)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.0.6)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.0.7)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.9.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (21.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.1.2)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.0.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.4.3)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.3.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.0.9)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.0.7)\n",
            "Requirement already satisfied: thinc<8.1.0,>=8.0.14 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (8.0.17)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (63.1.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (4.64.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.21.6)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.6.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.8.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.0.9)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (5.2.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.26.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2022.6.15)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.1.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.3)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (8.1.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from click<9.0.0,>=7.1.1->typer<0.5.0,>=0.3.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (4.12.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.1.1)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting bert-extractive-summarizer\n",
            "  Using cached bert_extractive_summarizer-0.10.1-py3-none-any.whl (25 kB)\n",
            "Collecting transformers\n",
            "  Using cached transformers-4.20.1-py3-none-any.whl (4.4 MB)\n",
            "Collecting scikit-learn\n",
            "  Using cached scikit_learn-1.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (24.8 MB)\n",
            "Collecting spacy\n",
            "  Using cached spacy-3.3.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.2 MB)\n",
            "Collecting numpy>=1.14.6\n",
            "  Using cached numpy-1.21.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n",
            "Collecting joblib>=0.11\n",
            "  Using cached joblib-1.1.0-py2.py3-none-any.whl (306 kB)\n",
            "Collecting scipy>=1.1.0\n",
            "  Using cached scipy-1.7.3-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (38.1 MB)\n",
            "Collecting threadpoolctl>=2.0.0\n",
            "  Using cached threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
            "Collecting cymem<2.1.0,>=2.0.2\n",
            "  Using cached cymem-2.0.6-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35 kB)\n",
            "Collecting langcodes<4.0.0,>=3.2.0\n",
            "  Using cached langcodes-3.3.0-py3-none-any.whl (181 kB)\n",
            "Collecting spacy-legacy<3.1.0,>=3.0.9\n",
            "  Using cached spacy_legacy-3.0.9-py2.py3-none-any.whl (20 kB)\n",
            "Collecting setuptools\n",
            "  Using cached setuptools-63.1.0-py3-none-any.whl (1.2 MB)\n",
            "Collecting spacy-loggers<2.0.0,>=1.0.0\n",
            "  Using cached spacy_loggers-1.0.2-py3-none-any.whl (7.2 kB)\n",
            "Collecting catalogue<2.1.0,>=2.0.6\n",
            "  Using cached catalogue-2.0.7-py3-none-any.whl (17 kB)\n",
            "Collecting preshed<3.1.0,>=3.0.2\n",
            "  Using cached preshed-3.0.6-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (125 kB)\n",
            "Collecting requests<3.0.0,>=2.13.0\n",
            "  Using cached requests-2.28.1-py3-none-any.whl (62 kB)\n",
            "Collecting tqdm<5.0.0,>=4.38.0\n",
            "  Using cached tqdm-4.64.0-py2.py3-none-any.whl (78 kB)\n",
            "Collecting srsly<3.0.0,>=2.4.3\n",
            "  Using cached srsly-2.4.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (457 kB)\n",
            "Collecting typing-extensions<4.2.0,>=3.7.4\n",
            "  Using cached typing_extensions-4.1.1-py3-none-any.whl (26 kB)\n",
            "Collecting thinc<8.1.0,>=8.0.14\n",
            "  Using cached thinc-8.0.17-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (660 kB)\n",
            "Collecting jinja2\n",
            "  Using cached Jinja2-3.1.2-py3-none-any.whl (133 kB)\n",
            "Collecting pathy>=0.3.5\n",
            "  Using cached pathy-0.6.2-py3-none-any.whl (42 kB)\n",
            "Collecting murmurhash<1.1.0,>=0.28.0\n",
            "  Using cached murmurhash-1.0.7-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21 kB)\n",
            "Collecting wasabi<1.1.0,>=0.9.1\n",
            "  Using cached wasabi-0.9.1-py3-none-any.whl (26 kB)\n",
            "Collecting pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4\n",
            "  Using cached pydantic-1.8.2-cp37-cp37m-manylinux2014_x86_64.whl (10.1 MB)\n",
            "Collecting packaging>=20.0\n",
            "  Using cached packaging-21.3-py3-none-any.whl (40 kB)\n",
            "Collecting blis<0.8.0,>=0.4.0\n",
            "  Using cached blis-0.7.8-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.2 MB)\n",
            "Collecting typer<0.5.0,>=0.3.0\n",
            "  Using cached typer-0.4.2-py3-none-any.whl (27 kB)\n",
            "Collecting zipp>=0.5\n",
            "  Using cached zipp-3.8.0-py3-none-any.whl (5.4 kB)\n",
            "Collecting pyparsing!=3.0.5,>=2.0.2\n",
            "  Using cached pyparsing-3.0.9-py3-none-any.whl (98 kB)\n",
            "Collecting smart-open<6.0.0,>=5.2.1\n",
            "  Using cached smart_open-5.2.1-py3-none-any.whl (58 kB)\n",
            "Collecting idna<4,>=2.5\n",
            "  Using cached idna-3.3-py3-none-any.whl (61 kB)\n",
            "Collecting urllib3<1.27,>=1.21.1\n",
            "  Using cached urllib3-1.26.10-py2.py3-none-any.whl (139 kB)\n",
            "Collecting charset-normalizer<3,>=2\n",
            "  Using cached charset_normalizer-2.1.0-py3-none-any.whl (39 kB)\n",
            "Collecting certifi>=2017.4.17\n",
            "  Using cached certifi-2022.6.15-py3-none-any.whl (160 kB)\n",
            "Collecting click<9.0.0,>=7.1.1\n",
            "  Using cached click-8.1.3-py3-none-any.whl (96 kB)\n",
            "Collecting importlib-metadata\n",
            "  Using cached importlib_metadata-4.12.0-py3-none-any.whl (21 kB)\n",
            "Collecting MarkupSafe>=2.0\n",
            "  Using cached MarkupSafe-2.1.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Using cached tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Using cached huggingface_hub-0.8.1-py3-none-any.whl (101 kB)\n",
            "Collecting pyyaml>=5.1\n",
            "  Using cached PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "Collecting regex!=2019.12.17\n",
            "  Using cached regex-2022.7.9-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (749 kB)\n",
            "Collecting filelock\n",
            "  Using cached filelock-3.7.1-py3-none-any.whl (10 kB)\n",
            "Installing collected packages: zipp, typing-extensions, importlib-metadata, urllib3, pyparsing, numpy, murmurhash, idna, cymem, click, charset-normalizer, certifi, catalogue, wasabi, typer, tqdm, srsly, smart-open, setuptools, requests, pyyaml, pydantic, preshed, packaging, MarkupSafe, filelock, blis, tokenizers, threadpoolctl, thinc, spacy-loggers, spacy-legacy, scipy, regex, pathy, langcodes, joblib, jinja2, huggingface-hub, transformers, spacy, scikit-learn, bert-extractive-summarizer\n",
            "  Attempting uninstall: zipp\n",
            "    Found existing installation: zipp 3.8.0\n",
            "    Uninstalling zipp-3.8.0:\n",
            "      Successfully uninstalled zipp-3.8.0\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing-extensions 4.1.1\n",
            "    Uninstalling typing-extensions-4.1.1:\n",
            "      Successfully uninstalled typing-extensions-4.1.1\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib-metadata 4.12.0\n",
            "    Uninstalling importlib-metadata-4.12.0:\n",
            "      Successfully uninstalled importlib-metadata-4.12.0\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.26.10\n",
            "    Uninstalling urllib3-1.26.10:\n",
            "      Successfully uninstalled urllib3-1.26.10\n",
            "  Attempting uninstall: pyparsing\n",
            "    Found existing installation: pyparsing 3.0.9\n",
            "    Uninstalling pyparsing-3.0.9:\n",
            "      Successfully uninstalled pyparsing-3.0.9\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.21.6\n",
            "    Uninstalling numpy-1.21.6:\n",
            "      Successfully uninstalled numpy-1.21.6\n",
            "  Attempting uninstall: murmurhash\n",
            "    Found existing installation: murmurhash 1.0.7\n",
            "    Uninstalling murmurhash-1.0.7:\n",
            "      Successfully uninstalled murmurhash-1.0.7\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.3\n",
            "    Uninstalling idna-3.3:\n",
            "      Successfully uninstalled idna-3.3\n",
            "  Attempting uninstall: cymem\n",
            "    Found existing installation: cymem 2.0.6\n",
            "    Uninstalling cymem-2.0.6:\n",
            "      Successfully uninstalled cymem-2.0.6\n",
            "  Attempting uninstall: click\n",
            "    Found existing installation: click 8.1.3\n",
            "    Uninstalling click-8.1.3:\n",
            "      Successfully uninstalled click-8.1.3\n",
            "  Attempting uninstall: charset-normalizer\n",
            "    Found existing installation: charset-normalizer 2.1.0\n",
            "    Uninstalling charset-normalizer-2.1.0:\n",
            "      Successfully uninstalled charset-normalizer-2.1.0\n",
            "  Attempting uninstall: certifi\n",
            "    Found existing installation: certifi 2022.6.15\n",
            "    Uninstalling certifi-2022.6.15:\n",
            "      Successfully uninstalled certifi-2022.6.15\n",
            "  Attempting uninstall: catalogue\n",
            "    Found existing installation: catalogue 2.0.7\n",
            "    Uninstalling catalogue-2.0.7:\n",
            "      Successfully uninstalled catalogue-2.0.7\n",
            "  Attempting uninstall: wasabi\n",
            "    Found existing installation: wasabi 0.9.1\n",
            "    Uninstalling wasabi-0.9.1:\n",
            "      Successfully uninstalled wasabi-0.9.1\n",
            "  Attempting uninstall: typer\n",
            "    Found existing installation: typer 0.4.2\n",
            "    Uninstalling typer-0.4.2:\n",
            "      Successfully uninstalled typer-0.4.2\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.64.0\n",
            "    Uninstalling tqdm-4.64.0:\n",
            "      Successfully uninstalled tqdm-4.64.0\n",
            "  Attempting uninstall: srsly\n",
            "    Found existing installation: srsly 2.4.3\n",
            "    Uninstalling srsly-2.4.3:\n",
            "      Successfully uninstalled srsly-2.4.3\n",
            "  Attempting uninstall: smart-open\n",
            "    Found existing installation: smart-open 5.2.1\n",
            "    Uninstalling smart-open-5.2.1:\n",
            "      Successfully uninstalled smart-open-5.2.1\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 63.1.0\n",
            "    Uninstalling setuptools-63.1.0:\n",
            "      Successfully uninstalled setuptools-63.1.0\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.28.1\n",
            "    Uninstalling requests-2.28.1:\n",
            "      Successfully uninstalled requests-2.28.1\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 6.0\n",
            "    Uninstalling PyYAML-6.0:\n",
            "      Successfully uninstalled PyYAML-6.0\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 1.8.2\n",
            "    Uninstalling pydantic-1.8.2:\n",
            "      Successfully uninstalled pydantic-1.8.2\n",
            "  Attempting uninstall: preshed\n",
            "    Found existing installation: preshed 3.0.6\n",
            "    Uninstalling preshed-3.0.6:\n",
            "      Successfully uninstalled preshed-3.0.6\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 21.3\n",
            "    Uninstalling packaging-21.3:\n",
            "      Successfully uninstalled packaging-21.3\n",
            "  Attempting uninstall: MarkupSafe\n",
            "    Found existing installation: MarkupSafe 2.1.1\n",
            "    Uninstalling MarkupSafe-2.1.1:\n",
            "      Successfully uninstalled MarkupSafe-2.1.1\n",
            "  Attempting uninstall: filelock\n",
            "    Found existing installation: filelock 3.7.1\n",
            "    Uninstalling filelock-3.7.1:\n",
            "      Successfully uninstalled filelock-3.7.1\n",
            "  Attempting uninstall: blis\n",
            "    Found existing installation: blis 0.7.8\n",
            "    Uninstalling blis-0.7.8:\n",
            "      Successfully uninstalled blis-0.7.8\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.12.1\n",
            "    Uninstalling tokenizers-0.12.1:\n",
            "      Successfully uninstalled tokenizers-0.12.1\n",
            "  Attempting uninstall: threadpoolctl\n",
            "    Found existing installation: threadpoolctl 3.1.0\n",
            "    Uninstalling threadpoolctl-3.1.0:\n",
            "      Successfully uninstalled threadpoolctl-3.1.0\n",
            "  Attempting uninstall: thinc\n",
            "    Found existing installation: thinc 8.0.17\n",
            "    Uninstalling thinc-8.0.17:\n",
            "      Successfully uninstalled thinc-8.0.17\n",
            "  Attempting uninstall: spacy-loggers\n",
            "    Found existing installation: spacy-loggers 1.0.2\n",
            "    Uninstalling spacy-loggers-1.0.2:\n",
            "      Successfully uninstalled spacy-loggers-1.0.2\n",
            "  Attempting uninstall: spacy-legacy\n",
            "    Found existing installation: spacy-legacy 3.0.9\n",
            "    Uninstalling spacy-legacy-3.0.9:\n",
            "      Successfully uninstalled spacy-legacy-3.0.9\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.7.3\n",
            "    Uninstalling scipy-1.7.3:\n",
            "      Successfully uninstalled scipy-1.7.3\n",
            "  Attempting uninstall: regex\n",
            "    Found existing installation: regex 2022.7.9\n",
            "    Uninstalling regex-2022.7.9:\n",
            "      Successfully uninstalled regex-2022.7.9\n",
            "  Attempting uninstall: pathy\n",
            "    Found existing installation: pathy 0.6.2\n",
            "    Uninstalling pathy-0.6.2:\n",
            "      Successfully uninstalled pathy-0.6.2\n",
            "  Attempting uninstall: langcodes\n",
            "    Found existing installation: langcodes 3.3.0\n",
            "    Uninstalling langcodes-3.3.0:\n",
            "      Successfully uninstalled langcodes-3.3.0\n",
            "  Attempting uninstall: joblib\n",
            "    Found existing installation: joblib 1.1.0\n",
            "    Uninstalling joblib-1.1.0:\n",
            "      Successfully uninstalled joblib-1.1.0\n",
            "  Attempting uninstall: jinja2\n",
            "    Found existing installation: Jinja2 3.1.2\n",
            "    Uninstalling Jinja2-3.1.2:\n",
            "      Successfully uninstalled Jinja2-3.1.2\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.8.1\n",
            "    Uninstalling huggingface-hub-0.8.1:\n",
            "      Successfully uninstalled huggingface-hub-0.8.1\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.20.1\n",
            "    Uninstalling transformers-4.20.1:\n",
            "      Successfully uninstalled transformers-4.20.1\n",
            "  Attempting uninstall: spacy\n",
            "    Found existing installation: spacy 3.3.1\n",
            "    Uninstalling spacy-3.3.1:\n",
            "      Successfully uninstalled spacy-3.3.1\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.0.2\n",
            "    Uninstalling scikit-learn-1.0.2:\n",
            "      Successfully uninstalled scikit-learn-1.0.2\n",
            "  Attempting uninstall: bert-extractive-summarizer\n",
            "    Found existing installation: bert-extractive-summarizer 0.10.1\n",
            "    Uninstalling bert-extractive-summarizer-0.10.1:\n",
            "      Successfully uninstalled bert-extractive-summarizer-0.10.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.28.1 which is incompatible.\n",
            "flask 1.1.4 requires click<8.0,>=5.1, but you have click 8.1.3 which is incompatible.\n",
            "flask 1.1.4 requires Jinja2<3.0,>=2.10.1, but you have jinja2 3.1.2 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed MarkupSafe-2.1.1 bert-extractive-summarizer-0.10.1 blis-0.7.8 catalogue-2.0.7 certifi-2022.6.15 charset-normalizer-2.1.0 click-8.1.3 cymem-2.0.6 filelock-3.7.1 huggingface-hub-0.8.1 idna-3.3 importlib-metadata-4.12.0 jinja2-3.1.2 joblib-1.1.0 langcodes-3.3.0 murmurhash-1.0.7 numpy-1.21.6 packaging-21.3 pathy-0.6.2 preshed-3.0.6 pydantic-1.8.2 pyparsing-3.0.9 pyyaml-6.0 regex-2022.7.9 requests-2.28.1 scikit-learn-1.0.2 scipy-1.7.3 setuptools-63.1.0 smart-open-5.2.1 spacy-3.3.1 spacy-legacy-3.0.9 spacy-loggers-1.0.2 srsly-2.4.3 thinc-8.0.17 threadpoolctl-3.1.0 tokenizers-0.12.1 tqdm-4.64.0 transformers-4.20.1 typer-0.4.2 typing-extensions-4.1.1 urllib3-1.26.10 wasabi-0.9.1 zipp-3.8.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "_distutils_hack",
                  "importlib_metadata",
                  "numpy",
                  "pkg_resources",
                  "setuptools",
                  "zipp"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (3.3.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.6)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.3.0)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.7)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.1.2)\n",
            "Requirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.1.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.21.6)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.6)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.8.2)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.64.0)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.2)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.6.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.28.1)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.9.1)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.7.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (21.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy) (63.1.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.7)\n",
            "Requirement already satisfied: thinc<8.1.0,>=8.0.14 in /usr/local/lib/python3.7/dist-packages (from spacy) (8.0.17)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy) (3.8.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy) (3.0.9)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy) (5.2.1)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.1.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.6.15)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.10)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy) (8.1.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from click<9.0.0,>=7.1.1->typer<0.5.0,>=0.3.0->spacy) (4.12.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy) (2.1.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk) (1.1.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk) (2022.7.9)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk) (8.1.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk) (4.64.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from click->nltk) (4.12.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->click->nltk) (3.8.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->click->nltk) (4.1.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pywsd==1.0.2 in /usr/local/lib/python3.7/dist-packages (1.0.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pywsd==1.0.2) (1.21.6)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from pywsd==1.0.2) (3.7)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk->pywsd==1.0.2) (2022.7.9)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk->pywsd==1.0.2) (8.1.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk->pywsd==1.0.2) (4.64.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk->pywsd==1.0.2) (1.1.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from click->nltk->pywsd==1.0.2) (4.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->click->nltk->pywsd==1.0.2) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->click->nltk->pywsd==1.0.2) (3.8.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install gensim\n",
        "!pip install git+https://github.com/boudinfl/pke.git\n",
        "!python -m spacy download en\n",
        "!pip install bert-extractive-summarizer --upgrade --force-reinstall\n",
        "# !pip install spacy==2.1.3 --upgrade --force-reinstall\n",
        "!pip install spacy\n",
        "!pip install -U nltk\n",
        "!pip install pywsd==1.0.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "24ZzZs4YwwWU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33cbb3fd-126c-4699-9d0d-0d14dd0c975f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading collection 'popular'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Package cmudict is already up-to-date!\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Package genesis is already up-to-date!\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Package inaugural is already up-to-date!\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Package names is already up-to-date!\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Package stopwords is already up-to-date!\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Package treebank is already up-to-date!\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    |   Package omw is already up-to-date!\n",
            "[nltk_data]    | Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]    |   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet2021 to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet2021 is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet31 to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet31 is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Package words is already up-to-date!\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Package punkt is already up-to-date!\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
            "[nltk_data]    |       to-date!\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection popular\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('popular')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nIlHsAINwwWV"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "## BERT Extractive Summarizer\n",
        "Summarize the text using BERT extractive summarizer. This is used to find important sentences and useful sentences from the complete text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "xRjgYvhhwwWX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac49ddf8-20d6-445f-b578-22d959a4e91b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (0.0.53)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses) (1.15.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from sacremoses) (2022.7.9)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sacremoses) (4.64.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses) (8.1.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from click->sacremoses) (4.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->click->sacremoses) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->click->sacremoses) (3.8.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Nile River fed Egyptian civilization for hundreds of years. It begins near the equator in Africa and flows north to the Mediterranean Sea. This soil was fertile, which means it was good for growing crops. Red Land, Black Land The ancient Egyptians lived in narrow bands of land on each side of the Nile. They called this region the black land because of the fertile soil that the floods deposited. The red land was the barren desert beyond the fertile region. Isolation The harsh desert acted as a barrier to keep out enemies. When the birds arrived, the annual flood waters would soon follow. Working together, they dug irrigation canals that carried river water to dry areas. These innovative, or new, techniques gave them more farmland. They were the first to grind wheat into flour and to mix the flour with yeast and water to make dough rise into bread. Egyptians often painted walls white to reflect the blazing heat. Poorer Egyptians simply went to the roof to cool off after sunset. They were probably the first people in the world to mine turquoise. One ancient painting even shows a man ready to hit a catfish with a wooden hammer. A boomerang is a curved stick that returns to the person who threw it.) Eventually, Egyptians equipped their reed boats with sails and oars. Going south, they raised a sail and let the winds that blew in that direction push them. The Nile provided so well for Egyptians that sometimes they had surpluses, or more goods than they needed. Ancient Egypt had no money, so people exchanged goods that they grew or made. This prosperity made life easier and provided greater opportunities for many Egyptians. For example, some ancient Egyptians learned to be scribes, people whose job was to write and keep records. Some skilled artisans erected stone or brick houses and temples. These traders took Egyptian products such as scrolls, linen, gold, and jewelry. Egyptians created a government that divided the empire into 42 provinces. Many officials worked to keep the provinces running smoothly. Priests followed formal rituals and took care of the temples. Before entering a temple, a priest bathed and put on special linen garments and white sandals. In Egypt, people became slaves if they owed a debt, committed a crime, or were captured in war. Unlike other ancient African cultures, in Egyptian society men and women had fairly equal rights. Almost all Egyptians married when they were in their early teens. As in many ancient societies, much of the knowledge of Egypt came about as priests studied the world to find ways to please the gods. Doctors believed that the heart controlled thought and the brain circulated blood, which is the opposite of what is known now. Hieroglyphs Hieroglyphs are pictures that stand for different words or sounds. Early Egyptians created a hieroglyphic system with about 700 characters. Egyptians cut the stems into strips, pressed them, and dried them into sheets that could be rolled into scrolls. Legend says a king named Narmer united Upper and Lower Egypt. Some historians think Narmer actually represents several kings who gradually joined the two lands. It combined the red Crown of Lower Egypt with the white Crown of Upper Egypt. When a king died, one of his children usually took his place as ruler. The order in which members of a royal family inherit a throne is called the succession. Historians divide ancient Egyptian dynasties into the Old Kingdom, the Middle Kingdom, and the New Kingdom. Because the pharaoh was thought to be a god, government and religion were not separate in ancient Egypt. The first rulers of Egypt were often buried in an underground tomb topped by mud brick. They replaced the mud brick with a small pyramid of brick or stone. A pyramid is a structure shaped like a triangle, with four sides that meet at a point. It is called a step pyramid because its sides rise in a series of giant steps. He ordered the construction of the largest pyramid ever built. These tools were much softer than the iron tools developed later. Farmers did the heavy labor of hauling stone during the season when the Nile flooded their fields. One reason is that the pyramids drew attention to the tombs inside them. Grave robbers broke into the tombs to steal the treasure buried with the pharaohs. This way, the pharaohs hoped to protect their bodies and treasures from robbers. This was to confuse grave robbers about which passage to take. A sculpture of a dead pharaoh had “perfect” features, no matter how he really looked. Artists also followed strict rules about how to portray humans. Such activities included growing and preparing food, caring for animals, and building boats. Only a secret tomb built for a New Kingdom pharaoh was ever found with much of its treasure untouched. By about 2130 B.C., Egyptian kings began to lose their power to local rulers of the provinces.\n"
          ]
        }
      ],
      "source": [
        "!pip install sacremoses\n",
        "from summarizer import Summarizer\n",
        "\n",
        "f = open(\"/content/drive/MyDrive/AutomaticMCQGenerator/full_text.txt\",\"r\")\n",
        "full_text = f.read()\n",
        "\n",
        "model = Summarizer()\n",
        "result = model(full_text, min_length=60, max_length = 500 , ratio = 0.4)\n",
        "\n",
        "summarized_text = ''.join(result)\n",
        "print (summarized_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rO9a8u6FwwWY"
      },
      "source": [
        "## Keyword Extraction\n",
        "Get important keywords from the text and filter those keywords that are present in the summarized text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "SUy3a7o7wwWZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0298dc56-0b50-43a3-fe5d-2ebc1bd99482"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['nile river', 'egyptians', 'egypt', 'nile', 'euphrates', 'tigris', 'old kingdom', 'crown', 'red land', 'longest river', 'narmer united upper', 'africa', 'mediterranean sea', 'hyksos', 'black land', 'new kingdom', 'ethiopia', 'middle kingdom', 'legend', 'lower egypt']\n",
            "['nile river', 'egyptians', 'egypt', 'nile', 'old kingdom', 'crown', 'red land', 'narmer united upper', 'africa', 'mediterranean sea', 'black land', 'new kingdom', 'middle kingdom', 'legend', 'lower egypt']\n"
          ]
        }
      ],
      "source": [
        "import pprint\n",
        "import itertools\n",
        "import re\n",
        "import pke\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "def get_nouns_multipartite(text):\n",
        "    out=[]\n",
        "\n",
        "    extractor = pke.unsupervised.MultipartiteRank()\n",
        "    stoplist = list(string.punctuation)\n",
        "    stoplist += ['-lrb-', '-rrb-', '-lcb-', '-rcb-', '-lsb-', '-rsb-']\n",
        "    stoplist += stopwords.words('english')\n",
        "    extractor.load_document(input=text,stoplist=stoplist)\n",
        "    #    not contain punctuation marks or stopwords as candidates.\n",
        "    pos = {'PROPN'}\n",
        "    #pos = {'VERB', 'ADJ', 'NOUN'}\n",
        "    extractor.candidate_selection(pos=pos)\n",
        "    # 4. build the Multipartite graph and rank candidates using random walk,\n",
        "    #    alpha controls the weight adjustment mechanism, see TopicRank for\n",
        "    #    threshold/method parameters.\n",
        "    extractor.candidate_weighting(alpha=1.1,\n",
        "                                  threshold=0.75,\n",
        "                                  method='average')\n",
        "    keyphrases = extractor.get_n_best(n=20)\n",
        "\n",
        "    for key in keyphrases:\n",
        "        out.append(key[0])\n",
        "\n",
        "    return out\n",
        "\n",
        "keywords = get_nouns_multipartite(full_text) \n",
        "print (keywords)\n",
        "filtered_keys=[]\n",
        "for keyword in keywords:\n",
        "    if keyword.lower() in summarized_text.lower():\n",
        "        filtered_keys.append(keyword)\n",
        "        \n",
        "print (filtered_keys)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-6oQmRJwwWa"
      },
      "source": [
        "## Sentence Mapping\n",
        "For each keyword get the sentences from the summarized text containing that keyword. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "osS6ZnCiwwWb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad7a362c-21af-4c53-f5a7-a60553eb2c54"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: flashtext in /usr/local/lib/python3.7/dist-packages (2.7)\n",
            "{'nile river': ['The Nile River fed Egyptian civilization for hundreds of years.'], 'egyptians': ['Egyptians cut the stems into strips, pressed them, and dried them into sheets that could be rolled into scrolls.', 'The Nile provided so well for Egyptians that sometimes they had surpluses, or more goods than they needed.', 'For example, some ancient Egyptians learned to be scribes, people whose job was to write and keep records.', 'Red Land, Black Land The ancient Egyptians lived in narrow bands of land on each side of the Nile.', 'This prosperity made life easier and provided greater opportunities for many Egyptians.', 'Egyptians created a government that divided the empire into 42 provinces.', 'Early Egyptians created a hieroglyphic system with about 700 characters.', 'Eventually, Egyptians equipped their reed boats with sails and oars.', 'Poorer Egyptians simply went to the roof to cool off after sunset.', 'Almost all Egyptians married when they were in their early teens.', 'Egyptians often painted walls white to reflect the blazing heat.'], 'egypt': ['As in many ancient societies, much of the knowledge of Egypt came about as priests studied the world to find ways to please the gods.', 'Because the pharaoh was thought to be a god, government and religion were not separate in ancient Egypt.', 'In Egypt, people became slaves if they owed a debt, committed a crime, or were captured in war.', 'The first rulers of Egypt were often buried in an underground tomb topped by mud brick.', 'Ancient Egypt had no money, so people exchanged goods that they grew or made.', 'It combined the red Crown of Lower Egypt with the white Crown of Upper Egypt.'], 'nile': ['The Nile provided so well for Egyptians that sometimes they had surpluses, or more goods than they needed.', 'Red Land, Black Land The ancient Egyptians lived in narrow bands of land on each side of the Nile.', 'Farmers did the heavy labor of hauling stone during the season when the Nile flooded their fields.'], 'old kingdom': ['Historians divide ancient Egyptian dynasties into the Old Kingdom, the Middle Kingdom, and the New Kingdom.'], 'crown': ['It combined the red Crown of Lower Egypt with the white Crown of Upper Egypt.', 'It combined the red Crown of Lower Egypt with the white Crown of Upper Egypt.'], 'red land': ['Red Land, Black Land The ancient Egyptians lived in narrow bands of land on each side of the Nile.', 'The red land was the barren desert beyond the fertile region.'], 'narmer united upper': ['Legend says a king named Narmer united Upper and Lower Egypt.'], 'africa': ['It begins near the equator in Africa and flows north to the Mediterranean Sea.'], 'mediterranean sea': ['It begins near the equator in Africa and flows north to the Mediterranean Sea.'], 'black land': ['Red Land, Black Land The ancient Egyptians lived in narrow bands of land on each side of the Nile.', 'They called this region the black land because of the fertile soil that the floods deposited.'], 'new kingdom': ['Historians divide ancient Egyptian dynasties into the Old Kingdom, the Middle Kingdom, and the New Kingdom.', 'Only a secret tomb built for a New Kingdom pharaoh was ever found with much of its treasure untouched.'], 'middle kingdom': ['Historians divide ancient Egyptian dynasties into the Old Kingdom, the Middle Kingdom, and the New Kingdom.'], 'legend': ['Legend says a king named Narmer united Upper and Lower Egypt.'], 'lower egypt': ['It combined the red Crown of Lower Egypt with the white Crown of Upper Egypt.', 'Legend says a king named Narmer united Upper and Lower Egypt.']}\n"
          ]
        }
      ],
      "source": [
        "!pip install flashtext\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from flashtext import KeywordProcessor\n",
        "\n",
        "def tokenize_sentences(text):\n",
        "    sentences = [sent_tokenize(text)]\n",
        "    sentences = [y for x in sentences for y in x]\n",
        "    # Remove any short sentences less than 20 letters.\n",
        "    sentences = [sentence.strip() for sentence in sentences if len(sentence) > 20]\n",
        "    return sentences\n",
        "\n",
        "def get_sentences_for_keyword(keywords, sentences):\n",
        "    keyword_processor = KeywordProcessor()\n",
        "    keyword_sentences = {}\n",
        "    for word in keywords:\n",
        "        keyword_sentences[word] = []\n",
        "        keyword_processor.add_keyword(word)\n",
        "    for sentence in sentences:\n",
        "        keywords_found = keyword_processor.extract_keywords(sentence)\n",
        "        for key in keywords_found:\n",
        "            keyword_sentences[key].append(sentence)\n",
        "\n",
        "    for key in keyword_sentences.keys():\n",
        "        values = keyword_sentences[key]\n",
        "        values = sorted(values, key=len, reverse=True)\n",
        "        keyword_sentences[key] = values\n",
        "    return keyword_sentences\n",
        "\n",
        "sentences = tokenize_sentences(summarized_text)\n",
        "keyword_sentence_mapping = get_sentences_for_keyword(filtered_keys, sentences)\n",
        "        \n",
        "print (keyword_sentence_mapping)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B9QIkJKTwwWc"
      },
      "source": [
        "## Generate MCQ\n",
        "Get distractors (wrong answer choices) from Wordnet/Conceptnet and generate MCQ Questions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ztd04d6MwwWd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfd856da-eb65-4e31-a22b-3fd200870d2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#############################################################################\n",
            "NOTE::::::::  Since the algorithm might have errors along the way, wrong answer choices generated might not be correct for some questions. \n",
            "#############################################################################\n",
            "\n",
            "\n",
            "1)  _______  cut the stems into strips, pressed them, and dried them into sheets that could be rolled into scrolls.\n",
            "\t a )   Angolan\n",
            "\t b )   Egyptians\n",
            "\t c )   Algerian\n",
            "\t d )   Bantu\n",
            "\n",
            "More options:  ['Basotho', 'Beninese', 'Berber', 'Black African', 'Burundian', 'Cameroonian', 'Carthaginian', 'Chadian', 'Chewa', 'Congolese', 'Djiboutian', 'Egyptian', 'Ethiopian', 'Eurafrican', 'Ewe', 'Fulani'] \n",
            "\n",
            "\n",
            "2) As in many ancient societies, much of the knowledge of  _______  came about as priests studied the world to find ways to please the gods.\n",
            "\t a )   Egypt\n",
            "\t b )   Kuwait\n",
            "\t c )   Iraq\n",
            "\t d )   Saudi Arabia\n",
            "\n",
            "More options:  ['Jordan', 'Israel', 'Fertile Crescent', 'Turkey', 'Iran', 'Lebanon', 'Shari', 'Mauritania', 'Nigeria', 'Somali peninsula', 'Sierra Leone', 'Malawi', 'North Africa', 'Senegal', 'Mozambique', 'Lake Tanganyika'] \n",
            "\n",
            "\n",
            "3) The  _______  provided so well for Egyptians that sometimes they had surpluses, or more goods than they needed.\n",
            "\t a )   Nile\n",
            "\t b )   Buganda\n",
            "\t c )   Entebbe\n",
            "\t d )   Gulu\n",
            "\n",
            "More options:  ['Jinja', 'Lake Edward', 'kayunga', 'gulu', 'entebbe', 'Port Sudan', 'Omdurman', 'Darfur', 'Libyan Desert', 'Kordofan', 'Khartoum', 'Nubian Desert', 'Nyala', 'Aswan High Dam', 'Eastern Desert', 'Aswan'] \n",
            "\n",
            "\n",
            "4) It combined the red  _______  of Lower Egypt with the white  _______  of Upper Egypt.\n",
            "\t a )   Academic Degree\n",
            "\t b )   Crown\n",
            "\t c )   Aliyah\n",
            "\t d )   Academy Award\n",
            "\n",
            "More options:  ['Cachet', 'Citation', 'Decoration', 'Emmy', 'Letter', 'Mention', 'Nobel Prize', 'Pennant', 'Prix De Rome', 'Prix Goncourt', 'Trophy'] \n",
            "\n",
            "\n",
            "5) It begins near the equator in  _______  and flows north to the Mediterranean Sea.\n",
            "\t a )   Eurasia\n",
            "\t b )   Africa\n",
            "\t c )   Old World\n",
            "\t d )   Australia\n",
            "\n",
            "More options:  [] \n",
            "\n",
            "\n",
            "6)  _______  says a king named Narmer united Upper and Lower Egypt.\n",
            "\t a )   Love Story\n",
            "\t b )   Adventure Story\n",
            "\t c )   Fable\n",
            "\t d )   Legend\n",
            "\n",
            "More options:  ['Mystery', 'Myth', 'Parable', 'Plot', 'Short Story'] \n",
            "\n",
            "\n",
            "7) It combined the red Crown of  _______  with the white Crown of Upper Egypt.\n",
            "\t a )   Eastern Desert\n",
            "\t b )   Lower egypt\n",
            "\t c )   Aswan\n",
            "\t d )   Aswan High Dam\n",
            "\n",
            "More options:  ['Lake Nasser', 'Saqqara', 'Cairo', 'Luxor', 'Suez', 'Suez Canal'] \n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import json\n",
        "import re\n",
        "import random\n",
        "from pywsd.similarity import max_similarity\n",
        "from pywsd.lesk import adapted_lesk\n",
        "from pywsd.lesk import simple_lesk\n",
        "from pywsd.lesk import cosine_lesk\n",
        "from nltk.corpus import wordnet as wn\n",
        "\n",
        "# Distractors from Wordnet\n",
        "def get_distractors_wordnet(syn,word):\n",
        "    distractors=[]\n",
        "    word= word.lower()\n",
        "    orig_word = word\n",
        "    if len(word.split())>0:\n",
        "        word = word.replace(\" \",\"_\")\n",
        "    hypernym = syn.hypernyms()\n",
        "    if len(hypernym) == 0: \n",
        "        return distractors\n",
        "    for item in hypernym[0].hyponyms():\n",
        "        name = item.lemmas()[0].name()\n",
        "        #print (\"name \",name, \" word\",orig_word)\n",
        "        if name == orig_word:\n",
        "            continue\n",
        "        name = name.replace(\"_\",\" \")\n",
        "        name = \" \".join(w.capitalize() for w in name.split())\n",
        "        if name is not None and name not in distractors:\n",
        "            distractors.append(name)\n",
        "    return distractors\n",
        "\n",
        "def get_wordsense(sent,word):\n",
        "    word= word.lower()\n",
        "    \n",
        "    if len(word.split())>0:\n",
        "        word = word.replace(\" \",\"_\")\n",
        "    \n",
        "    \n",
        "    synsets = wn.synsets(word,'n')\n",
        "    if synsets:\n",
        "        wup = max_similarity(sent, word, 'wup', pos='n')\n",
        "        adapted_lesk_output =  adapted_lesk(sent, word, pos='n')\n",
        "        lowest_index = min (synsets.index(wup),synsets.index(adapted_lesk_output))\n",
        "        return synsets[lowest_index]\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "# Distractors from http://conceptnet.io/\n",
        "def get_distractors_conceptnet(word):\n",
        "    word = word.lower()\n",
        "    original_word= word\n",
        "    if (len(word.split())>0):\n",
        "        word = word.replace(\" \",\"_\")\n",
        "    distractor_list = [] \n",
        "    url = \"http://api.conceptnet.io/query?node=/c/en/%s/n&rel=/r/PartOf&start=/c/en/%s&limit=5\"%(word,word)\n",
        "    obj = requests.get(url).json()\n",
        "\n",
        "    for edge in obj['edges']:\n",
        "        link = edge['end']['term'] \n",
        "\n",
        "        url2 = \"http://api.conceptnet.io/query?node=%s&rel=/r/PartOf&end=%s&limit=10\"%(link,link)\n",
        "        obj2 = requests.get(url2).json()\n",
        "        for edge in obj2['edges']:\n",
        "            word2 = edge['start']['label']\n",
        "            if word2 not in distractor_list and original_word.lower() not in word2.lower():\n",
        "                distractor_list.append(word2)\n",
        "                   \n",
        "    return distractor_list\n",
        "\n",
        "key_distractor_list = {}\n",
        "\n",
        "for keyword in keyword_sentence_mapping:\n",
        "    wordsense = get_wordsense(keyword_sentence_mapping[keyword][0],keyword)\n",
        "    if wordsense:\n",
        "        distractors = get_distractors_wordnet(wordsense,keyword)\n",
        "        if len(distractors) ==0:\n",
        "            distractors = get_distractors_conceptnet(keyword)\n",
        "        if len(distractors) != 0:\n",
        "            key_distractor_list[keyword] = distractors\n",
        "    else:\n",
        "        \n",
        "        distractors = get_distractors_conceptnet(keyword)\n",
        "        if len(distractors) != 0:\n",
        "            key_distractor_list[keyword] = distractors"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Changing sentence to question\n",
        "\n",
        "Using a T5 transformer, sentence and keyword is changed to question."
      ],
      "metadata": {
        "id": "NITlm46H8NEb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "yGZH2uaPwwWf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        },
        "outputId": "e7f29689-613f-4953-c1d8-3618a6efef78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sentencepiece==0.1.94\n",
            "  Downloading sentencepiece-0.1.94-cp37-cp37m-manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 5.1 MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "  Attempting uninstall: sentencepiece\n",
            "    Found existing installation: sentencepiece 0.1.96\n",
            "    Uninstalling sentencepiece-0.1.96:\n",
            "      Successfully uninstalled sentencepiece-0.1.96\n",
            "Successfully installed sentencepiece-0.1.94\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "sentencepiece"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from transformers import T5ForConditionalGeneration,T5Tokenizer\n",
        "!pip install sentencepiece==0.1.94"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question_model = T5ForConditionalGeneration.from_pretrained('ramsrigouthamg/t5_squad_v1')\n",
        "question_tokenizer = T5Tokenizer.from_pretrained('t5-base')\n",
        "\n",
        "MAX_SEQ_LENGTH = 128"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205,
          "referenced_widgets": [
            "6e513d3b626d4f89b72700dbc95f6e59",
            "e5faf185ced5478b879c57cd24d14398",
            "116516809599497d99423f6ca70e4aa0",
            "8ce0ba8e7ea941df8aa531e118cab904",
            "d1afd9a12f0b4b668af8eed12c1a1ddb",
            "d0690a4579194b13b010b231bf0b8504",
            "fa655dafb7bb41a298938bfc21c50e7b",
            "37f43771dd354961ae24553166054695",
            "91d8b92434d8487d893c6b27ce0e035d",
            "9fede096f4be45fc827b2010e7018170",
            "3b73e6e47b454662b0cff7cba9d1d4c5",
            "b508858e88c044c8bf0edd934d53eea9",
            "95e7bcfddee540bf8a65470766512d5d",
            "bb6edd5eb1354ce9bec8aeea6e8bc050",
            "ff5934feb8284b16a2da3dfb91ce873a",
            "45a5bb02cd26471c8893d286ec2c92e7",
            "05e68380a67944a987f696a2c7a9d2eb",
            "a47410cd7ee44d61be9c1d152f2b6a30",
            "3d1dd659734a4be79dd899784b0d297f",
            "6df34545ebe44580ad422f1a47e5f431",
            "1d92a2ec954f4c2fbace4aadc1fde2e3",
            "e1a8fc91d51849f5ba682535abd41d73"
          ]
        },
        "id": "ODKO2Wiw8Sjm",
        "outputId": "b07220b7-77c1-4cd1-a0d3-89c0d1d0f1d9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/773k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6e513d3b626d4f89b72700dbc95f6e59"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.17k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b508858e88c044c8bf0edd934d53eea9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/models/t5/tokenization_t5.py:174: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
            "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
            "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
            "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
            "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_question(sentence,answer):\n",
        "  sentence = \" \".join(sentence.split()) \n",
        "  text = \"context: {} answer: {}\".format(sentence,answer)\n",
        "  max_len = 256\n",
        "  encoding = question_tokenizer.encode_plus(text,max_length=max_len, padding='max_length', return_tensors=\"pt\")\n",
        "\n",
        "  input_ids, attention_mask = encoding[\"input_ids\"], encoding[\"attention_mask\"]\n",
        "\n",
        "  outs = question_model.generate(input_ids=input_ids,\n",
        "                                  attention_mask=attention_mask,\n",
        "                                  early_stopping=True,\n",
        "                                  num_beams=5,\n",
        "                                  num_return_sequences=1,\n",
        "                                  no_repeat_ngram_size=2,\n",
        "                                  max_length=200)\n",
        "\n",
        "\n",
        "  dec = [question_tokenizer.decode(ids) for ids in outs]\n",
        "  Question = dec[0].replace(\"question:\",\"\")\n",
        "  Question= Question.strip()\n",
        "  return Question"
      ],
      "metadata": {
        "id": "pH--o5m28hKW"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "q = get_question(\"I love the color red.\",\"red\")\n",
        "q = q.replace(\"<pad>\",\" \")\n",
        "q = q.replace(\"</s>\",\" \")\n",
        "q = q.strip()\n",
        "print(q)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mhDX21mf8m8K",
        "outputId": "2dca4683-1bbb-4649-9f92-2820a6720b20"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What color do I love?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "index = 1\n",
        "print (\"#############################################################################\")\n",
        "print (\"NOTE::::::::  Since the algorithm might have errors along the way, wrong answer choices generated might not be correct for some questions. \")\n",
        "print (\"#############################################################################\\n\\n\")\n",
        "for each in key_distractor_list:\n",
        "    sentence = keyword_sentence_mapping[each][0]\n",
        "    pattern = re.compile(each, re.IGNORECASE)\n",
        "    # output = pattern.sub( \" _______ \", sentence)\n",
        "    output = get_question(sentence.lower(),each.lower())\n",
        "    output = output.replace(\"<pad>\",\" \")\n",
        "    output = output.replace(\"</s>\",\" \")\n",
        "    output = output.strip()\n",
        "    print (\"%s)\"%(index),output)\n",
        "    choices = [each.capitalize()] + key_distractor_list[each]\n",
        "    top4choices = choices[:4]\n",
        "    random.shuffle(top4choices)\n",
        "    optionchoices = ['a','b','c','d']\n",
        "    for idx,choice in enumerate(top4choices):\n",
        "        print (\"\\t\",optionchoices[idx],\")\",\" \",choice)\n",
        "    print (\"\\nMore options: \", choices[4:20],\"\\n\\n\")\n",
        "    index = index + 1\n",
        "    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mDxxvIdKArXm",
        "outputId": "2bf62460-d8af-4d8e-90a8-82b99a353db5"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#############################################################################\n",
            "NOTE::::::::  Since the algorithm might have errors along the way, wrong answer choices generated might not be correct for some questions. \n",
            "#############################################################################\n",
            "\n",
            "\n",
            "1) Who cut the stems into strips?\n",
            "\t a )   Bantu\n",
            "\t b )   Algerian\n",
            "\t c )   Angolan\n",
            "\t d )   Egyptians\n",
            "\n",
            "More options:  ['Basotho', 'Beninese', 'Berber', 'Black African', 'Burundian', 'Cameroonian', 'Carthaginian', 'Chadian', 'Chewa', 'Congolese', 'Djiboutian', 'Egyptian', 'Ethiopian', 'Eurafrican', 'Ewe', 'Fulani'] \n",
            "\n",
            "\n",
            "2) Priests studied the world to find ways to please the gods in what ancient society?\n",
            "\t a )   Kuwait\n",
            "\t b )   Egypt\n",
            "\t c )   Saudi Arabia\n",
            "\t d )   Iraq\n",
            "\n",
            "More options:  ['Jordan', 'Israel', 'Fertile Crescent', 'Turkey', 'Iran', 'Lebanon', 'Shari', 'Mauritania', 'Nigeria', 'Somali peninsula', 'Sierra Leone', 'Malawi', 'North Africa', 'Senegal', 'Mozambique', 'Lake Tanganyika'] \n",
            "\n",
            "\n",
            "3) What provided so well for egyptians that they had surpluses?\n",
            "\t a )   Nile\n",
            "\t b )   Gulu\n",
            "\t c )   Entebbe\n",
            "\t d )   Buganda\n",
            "\n",
            "More options:  ['Jinja', 'Lake Edward', 'kayunga', 'gulu', 'entebbe', 'Port Sudan', 'Omdurman', 'Darfur', 'Libyan Desert', 'Kordofan', 'Khartoum', 'Nubian Desert', 'Nyala', 'Aswan High Dam', 'Eastern Desert', 'Aswan'] \n",
            "\n",
            "\n",
            "4) What part of the upper egypt was white?\n",
            "\t a )   Crown\n",
            "\t b )   Aliyah\n",
            "\t c )   Academy Award\n",
            "\t d )   Academic Degree\n",
            "\n",
            "More options:  ['Cachet', 'Citation', 'Decoration', 'Emmy', 'Letter', 'Mention', 'Nobel Prize', 'Pennant', 'Prix De Rome', 'Prix Goncourt', 'Trophy'] \n",
            "\n",
            "\n",
            "5) Where does the equator begin?\n",
            "\t a )   Africa\n",
            "\t b )   Australia\n",
            "\t c )   Eurasia\n",
            "\t d )   Old World\n",
            "\n",
            "More options:  [] \n",
            "\n",
            "\n",
            "6) What says narmer united upper and lower egypt?\n",
            "\t a )   Adventure Story\n",
            "\t b )   Love Story\n",
            "\t c )   Fable\n",
            "\t d )   Legend\n",
            "\n",
            "More options:  ['Mystery', 'Myth', 'Parable', 'Plot', 'Short Story'] \n",
            "\n",
            "\n",
            "7) Which egypt had a red crown?\n",
            "\t a )   Aswan\n",
            "\t b )   Aswan High Dam\n",
            "\t c )   Eastern Desert\n",
            "\t d )   Lower egypt\n",
            "\n",
            "More options:  ['Lake Nasser', 'Saqqara', 'Cairo', 'Luxor', 'Suez', 'Suez Canal'] \n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deploy using Gradio"
      ],
      "metadata": {
        "id": "Qo7ZD4nI_Tir"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_gradio(full_text):\n",
        "  #Summarize\n",
        "  result = model(full_text, min_length=60, max_length = 500 , ratio = 0.4)\n",
        "  summarized_text = ''.join(result)\n",
        "  #Get nouns\n",
        "  keywords = get_nouns_multipartite(full_text) \n",
        "  filtered_keys=[]\n",
        "  for keyword in keywords:\n",
        "    if keyword.lower() in summarized_text.lower():\n",
        "      filtered_keys.append(keyword)\n",
        "  sentences = tokenize_sentences(summarized_text)\n",
        "  keyword_sentence_mapping = get_sentences_for_keyword(filtered_keys, sentences)\n",
        "  #Get distractors\n",
        "  key_distractor_list = {}\n",
        "  for keyword in keyword_sentence_mapping:\n",
        "      wordsense = get_wordsense(keyword_sentence_mapping[keyword][0],keyword)\n",
        "      if wordsense:\n",
        "          distractors = get_distractors_wordnet(wordsense,keyword)\n",
        "          if len(distractors) ==0:\n",
        "              distractors = get_distractors_conceptnet(keyword)\n",
        "          if len(distractors) != 0:\n",
        "              key_distractor_list[keyword] = distractors\n",
        "      else:        \n",
        "          distractors = get_distractors_conceptnet(keyword)\n",
        "          if len(distractors) != 0:\n",
        "              key_distractor_list[keyword] = distractors\n",
        "\n",
        "  index = 1\n",
        "  print (\"#############################################################################\")\n",
        "  print (\"NOTE::::::::  Since the algorithm might have errors along the way, wrong answer choices generated might not be correct for some questions. \")\n",
        "  print (\"#############################################################################\\n\\n\")\n",
        "  out = \"\"\n",
        "  for each in key_distractor_list:\n",
        "      sentence = keyword_sentence_mapping[each][0]\n",
        "      pattern = re.compile(each, re.IGNORECASE)\n",
        "      # output = pattern.sub( \" _______ \", sentence)\n",
        "      output = get_question(sentence.lower(),each.lower())\n",
        "      output = output.replace(\"<pad>\",\" \")\n",
        "      output = output.replace(\"</s>\",\" \")\n",
        "      output = output.strip()\n",
        "      # print (\"%s)\"%(index),output)\n",
        "      out = out + \"\\n\\n\\n\"+ str(index)+\". \"+output+\"\\n\"\n",
        "      choices = [each.capitalize()] + key_distractor_list[each]\n",
        "      top4choices = choices[:4]\n",
        "      random.shuffle(top4choices)\n",
        "      optionchoices = ['a','b','c','d']\n",
        "      curr_choices = \"\"\n",
        "      for idx,choice in enumerate(top4choices):\n",
        "          # print (\"\\t\",optionchoices[idx],\")\",\" \",choice)\n",
        "          out = out + \"\\t\"+optionchoices[idx]+\") \"+choice\n",
        "      # print (\"\\nMore options: \", choices[4:20],\"\\n\\n\")\n",
        "      index = index + 1\n",
        "  return out"
      ],
      "metadata": {
        "id": "o7h5xcx8SzkY"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = process_gradio(full_text)\n",
        "print(res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wnzT4sqkZGWS",
        "outputId": "192f9558-9932-4928-88d6-eb28ce6818e0"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#############################################################################\n",
            "NOTE::::::::  Since the algorithm might have errors along the way, wrong answer choices generated might not be correct for some questions. \n",
            "#############################################################################\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1. Who cut the stems into strips?\n",
            "\ta) Algerian\tb) Egyptians\tc) Bantu\td) Angolan\n",
            "\n",
            "\n",
            "2. Priests studied the world to find ways to please the gods in what ancient society?\n",
            "\ta) Iraq\tb) Egypt\tc) Kuwait\td) Saudi Arabia\n",
            "\n",
            "\n",
            "3. What provided so well for egyptians that they had surpluses?\n",
            "\ta) Buganda\tb) Nile\tc) Entebbe\td) Gulu\n",
            "\n",
            "\n",
            "4. What part of the upper egypt was white?\n",
            "\ta) Academic Degree\tb) Aliyah\tc) Crown\td) Academy Award\n",
            "\n",
            "\n",
            "5. Where does the equator begin?\n",
            "\ta) Eurasia\tb) Old World\tc) Africa\td) Australia\n",
            "\n",
            "\n",
            "6. What says narmer united upper and lower egypt?\n",
            "\ta) Adventure Story\tb) Fable\tc) Legend\td) Love Story\n",
            "\n",
            "\n",
            "7. Which egypt had a red crown?\n",
            "\ta) Aswan\tb) Eastern Desert\tc) Lower egypt\td) Aswan High Dam\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio\n",
        "import gradio as gr\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ExOtf0KQf7vh",
        "outputId": "81386c85-fef2-4cf3-f82c-35a803804f6e"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting gradio\n",
            "  Downloading gradio-3.0.24-py3-none-any.whl (5.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.1 MB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from gradio) (3.2.2)\n",
            "Requirement already satisfied: Jinja2 in /usr/local/lib/python3.7/dist-packages (from gradio) (3.1.2)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 44.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from gradio) (2.28.1)\n",
            "Collecting markdown-it-py[linkify,plugins]\n",
            "  Downloading markdown_it_py-2.1.0-py3-none-any.whl (84 kB)\n",
            "\u001b[K     |████████████████████████████████| 84 kB 3.0 MB/s \n",
            "\u001b[?25hCollecting httpx\n",
            "  Downloading httpx-0.23.0-py3-none-any.whl (84 kB)\n",
            "\u001b[K     |████████████████████████████████| 84 kB 2.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pydantic in /usr/local/lib/python3.7/dist-packages (from gradio) (1.8.2)\n",
            "Collecting ffmpy\n",
            "  Downloading ffmpy-0.3.0.tar.gz (4.8 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from gradio) (1.3.5)\n",
            "Collecting python-multipart\n",
            "  Downloading python-multipart-0.0.5.tar.gz (32 kB)\n",
            "Collecting pycryptodome\n",
            "  Downloading pycryptodome-3.15.0-cp35-abi3-manylinux2010_x86_64.whl (2.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3 MB 42.0 MB/s \n",
            "\u001b[?25hCollecting fsspec\n",
            "  Downloading fsspec-2022.5.0-py3-none-any.whl (140 kB)\n",
            "\u001b[K     |████████████████████████████████| 140 kB 55.5 MB/s \n",
            "\u001b[?25hCollecting orjson\n",
            "  Downloading orjson-3.7.7-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (272 kB)\n",
            "\u001b[K     |████████████████████████████████| 272 kB 51.1 MB/s \n",
            "\u001b[?25hCollecting analytics-python\n",
            "  Downloading analytics_python-1.4.0-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from gradio) (1.21.6)\n",
            "Collecting fastapi\n",
            "  Downloading fastapi-0.78.0-py3-none-any.whl (54 kB)\n",
            "\u001b[K     |████████████████████████████████| 54 kB 3.1 MB/s \n",
            "\u001b[?25hCollecting paramiko\n",
            "  Downloading paramiko-2.11.0-py2.py3-none-any.whl (212 kB)\n",
            "\u001b[K     |████████████████████████████████| 212 kB 60.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from gradio) (7.1.2)\n",
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Collecting uvicorn\n",
            "  Downloading uvicorn-0.18.2-py3-none-any.whl (57 kB)\n",
            "\u001b[K     |████████████████████████████████| 57 kB 4.7 MB/s \n",
            "\u001b[?25hCollecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 46.4 MB/s \n",
            "\u001b[?25hCollecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
            "Collecting asynctest==0.13.0\n",
            "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n",
            "\u001b[K     |████████████████████████████████| 94 kB 3.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->gradio) (21.4.0)\n",
            "Collecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[K     |████████████████████████████████| 144 kB 49.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from aiohttp->gradio) (4.1.1)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->gradio) (2.1.0)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.7/dist-packages (from yarl<2.0,>=1.0->aiohttp->gradio) (3.3)\n",
            "Requirement already satisfied: python-dateutil>2.1 in /usr/local/lib/python3.7/dist-packages (from analytics-python->gradio) (2.8.2)\n",
            "Collecting monotonic>=1.5\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from analytics-python->gradio) (1.15.0)\n",
            "Collecting backoff==1.10.0\n",
            "  Downloading backoff-1.10.0-py2.py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->gradio) (2022.6.15)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->gradio) (1.26.10)\n",
            "Collecting starlette==0.19.1\n",
            "  Downloading starlette-0.19.1-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.9 MB/s \n",
            "\u001b[?25hCollecting anyio<5,>=3.4.0\n",
            "  Downloading anyio-3.6.1-py3-none-any.whl (80 kB)\n",
            "\u001b[K     |████████████████████████████████| 80 kB 8.0 MB/s \n",
            "\u001b[?25hCollecting sniffio>=1.1\n",
            "  Downloading sniffio-1.2.0-py3-none-any.whl (10 kB)\n",
            "Collecting rfc3986[idna2008]<2,>=1.3\n",
            "  Downloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n",
            "Collecting httpcore<0.16.0,>=0.15.0\n",
            "  Downloading httpcore-0.15.0-py3-none-any.whl (68 kB)\n",
            "\u001b[K     |████████████████████████████████| 68 kB 6.1 MB/s \n",
            "\u001b[?25hCollecting h11<0.13,>=0.11\n",
            "  Downloading h11-0.12.0-py3-none-any.whl (54 kB)\n",
            "\u001b[K     |████████████████████████████████| 54 kB 3.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.7/dist-packages (from Jinja2->gradio) (2.1.1)\n",
            "Collecting mdurl~=0.1\n",
            "  Downloading mdurl-0.1.1-py3-none-any.whl (10 kB)\n",
            "Collecting linkify-it-py~=1.0\n",
            "  Downloading linkify_it_py-1.0.3-py3-none-any.whl (19 kB)\n",
            "Collecting mdit-py-plugins\n",
            "  Downloading mdit_py_plugins-0.3.0-py3-none-any.whl (43 kB)\n",
            "\u001b[K     |████████████████████████████████| 43 kB 1.3 MB/s \n",
            "\u001b[?25hCollecting uc-micro-py\n",
            "  Downloading uc_micro_py-1.0.1-py3-none-any.whl (6.2 kB)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->gradio) (1.4.3)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->gradio) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->gradio) (0.11.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->gradio) (2022.1)\n",
            "Collecting pynacl>=1.0.1\n",
            "  Downloading PyNaCl-1.5.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (856 kB)\n",
            "\u001b[K     |████████████████████████████████| 856 kB 40.8 MB/s \n",
            "\u001b[?25hCollecting cryptography>=2.5\n",
            "  Downloading cryptography-37.0.4-cp36-abi3-manylinux_2_24_x86_64.whl (4.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.1 MB 35.8 MB/s \n",
            "\u001b[?25hCollecting bcrypt>=3.1.3\n",
            "  Downloading bcrypt-3.2.2-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 723 kB/s \n",
            "\u001b[?25hRequirement already satisfied: cffi>=1.1 in /usr/local/lib/python3.7/dist-packages (from bcrypt>=3.1.3->paramiko->gradio) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.1->bcrypt>=3.1.3->paramiko->gradio) (2.21)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from uvicorn->gradio) (8.1.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from click>=7.0->uvicorn->gradio) (4.12.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->click>=7.0->uvicorn->gradio) (3.8.0)\n",
            "Building wheels for collected packages: ffmpy, python-multipart\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpy: filename=ffmpy-0.3.0-py3-none-any.whl size=4693 sha256=f46b3c76d6b9e5922bee5a07d6e079c399319bfed8d5c2da608e26db07b1a2c7\n",
            "  Stored in directory: /root/.cache/pip/wheels/13/e4/6c/e8059816e86796a597c6e6b0d4c880630f51a1fcfa0befd5e6\n",
            "  Building wheel for python-multipart (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-multipart: filename=python_multipart-0.0.5-py3-none-any.whl size=31671 sha256=cefe87a1cbccd8b6bf2db74fc1b53435dc55e20dadbb0581f61497c8ace588ab\n",
            "  Stored in directory: /root/.cache/pip/wheels/2c/41/7c/bfd1c180534ffdcc0972f78c5758f89881602175d48a8bcd2c\n",
            "Successfully built ffmpy python-multipart\n",
            "Installing collected packages: sniffio, mdurl, uc-micro-py, rfc3986, multidict, markdown-it-py, h11, frozenlist, anyio, yarl, starlette, pynacl, monotonic, mdit-py-plugins, linkify-it-py, httpcore, cryptography, bcrypt, backoff, asynctest, async-timeout, aiosignal, uvicorn, python-multipart, pydub, pycryptodome, paramiko, orjson, httpx, fsspec, ffmpy, fastapi, analytics-python, aiohttp, gradio\n",
            "Successfully installed aiohttp-3.8.1 aiosignal-1.2.0 analytics-python-1.4.0 anyio-3.6.1 async-timeout-4.0.2 asynctest-0.13.0 backoff-1.10.0 bcrypt-3.2.2 cryptography-37.0.4 fastapi-0.78.0 ffmpy-0.3.0 frozenlist-1.3.0 fsspec-2022.5.0 gradio-3.0.24 h11-0.12.0 httpcore-0.15.0 httpx-0.23.0 linkify-it-py-1.0.3 markdown-it-py-2.1.0 mdit-py-plugins-0.3.0 mdurl-0.1.1 monotonic-1.6 multidict-6.0.2 orjson-3.7.7 paramiko-2.11.0 pycryptodome-3.15.0 pydub-0.25.1 pynacl-1.5.0 python-multipart-0.0.5 rfc3986-1.5.0 sniffio-1.2.0 starlette-0.19.1 uc-micro-py-1.0.1 uvicorn-0.18.2 yarl-1.7.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "demo = gr.Interface(\n",
        "    process_gradio,\n",
        "    \"text\",\n",
        "    \"text\"\n",
        ")"
      ],
      "metadata": {
        "id": "bdeO00mVmoCH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "demo.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 643
        },
        "id": "LEh4jRrymSyR",
        "outputId": "9e2eb6cc-0b0f-43dd-fb78-00aa1355994f"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set `debug=True` in `launch()`\n",
            "Running on public URL: https://34739.gradio.app\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting, check out Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://34739.gradio.app\" width=\"900\" height=\"500\" allow=\"autoplay; camera; microphone;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<gradio.routes.App at 0x7ff01c4c6110>,\n",
              " 'http://127.0.0.1:7860/',\n",
              " 'https://34739.gradio.app')"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "pF2Mit8nmkmU"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "conda_pytorch_p36",
      "language": "python",
      "name": "conda_pytorch_p36"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "Automatic_MCQ_Generation.ipynb",
      "provenance": []
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6e513d3b626d4f89b72700dbc95f6e59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e5faf185ced5478b879c57cd24d14398",
              "IPY_MODEL_116516809599497d99423f6ca70e4aa0",
              "IPY_MODEL_8ce0ba8e7ea941df8aa531e118cab904"
            ],
            "layout": "IPY_MODEL_d1afd9a12f0b4b668af8eed12c1a1ddb"
          }
        },
        "e5faf185ced5478b879c57cd24d14398": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d0690a4579194b13b010b231bf0b8504",
            "placeholder": "​",
            "style": "IPY_MODEL_fa655dafb7bb41a298938bfc21c50e7b",
            "value": "Downloading: 100%"
          }
        },
        "116516809599497d99423f6ca70e4aa0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_37f43771dd354961ae24553166054695",
            "max": 791656,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_91d8b92434d8487d893c6b27ce0e035d",
            "value": 791656
          }
        },
        "8ce0ba8e7ea941df8aa531e118cab904": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9fede096f4be45fc827b2010e7018170",
            "placeholder": "​",
            "style": "IPY_MODEL_3b73e6e47b454662b0cff7cba9d1d4c5",
            "value": " 773k/773k [00:00&lt;00:00, 2.28MB/s]"
          }
        },
        "d1afd9a12f0b4b668af8eed12c1a1ddb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d0690a4579194b13b010b231bf0b8504": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa655dafb7bb41a298938bfc21c50e7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "37f43771dd354961ae24553166054695": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91d8b92434d8487d893c6b27ce0e035d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9fede096f4be45fc827b2010e7018170": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b73e6e47b454662b0cff7cba9d1d4c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b508858e88c044c8bf0edd934d53eea9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_95e7bcfddee540bf8a65470766512d5d",
              "IPY_MODEL_bb6edd5eb1354ce9bec8aeea6e8bc050",
              "IPY_MODEL_ff5934feb8284b16a2da3dfb91ce873a"
            ],
            "layout": "IPY_MODEL_45a5bb02cd26471c8893d286ec2c92e7"
          }
        },
        "95e7bcfddee540bf8a65470766512d5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_05e68380a67944a987f696a2c7a9d2eb",
            "placeholder": "​",
            "style": "IPY_MODEL_a47410cd7ee44d61be9c1d152f2b6a30",
            "value": "Downloading: 100%"
          }
        },
        "bb6edd5eb1354ce9bec8aeea6e8bc050": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3d1dd659734a4be79dd899784b0d297f",
            "max": 1199,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6df34545ebe44580ad422f1a47e5f431",
            "value": 1199
          }
        },
        "ff5934feb8284b16a2da3dfb91ce873a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1d92a2ec954f4c2fbace4aadc1fde2e3",
            "placeholder": "​",
            "style": "IPY_MODEL_e1a8fc91d51849f5ba682535abd41d73",
            "value": " 1.17k/1.17k [00:00&lt;00:00, 28.6kB/s]"
          }
        },
        "45a5bb02cd26471c8893d286ec2c92e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05e68380a67944a987f696a2c7a9d2eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a47410cd7ee44d61be9c1d152f2b6a30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3d1dd659734a4be79dd899784b0d297f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6df34545ebe44580ad422f1a47e5f431": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1d92a2ec954f4c2fbace4aadc1fde2e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1a8fc91d51849f5ba682535abd41d73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}